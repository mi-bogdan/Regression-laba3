<h2 align="center">Нейронные сети для решения задач классификации и регрессии</h2>

**Ссылки**:
- [VK - Шныра Богдан ИСТ-19б](https://vk.com/id404101172)


### Инструменты разработки

**Стек:**
- Python >= 3.10
- Pandas >= 1.5.2
- tabulate >= 0.9.0
- scikit-learn >= 1.2.0
- numpy >= 1.23.5


##### 1) Описание предметной области и постановка задачи:

  - [Набор данных YearPredictionMSD](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD)

##### 2) Информация о наборе данных:

Эти данные собраны для предсказания года выпуска песни по аудиофункциям. Песни в основном западные, коммерческие треки, выпущенные с 1922 по 2011 год, с пиком в 2000-х годах.
Всего 90 атрибутов: 12 = среднее значение тембра, 78 = ковариация тембра.
Первое значение — это год (цель) в диапазоне от 1922 до 2011.
Функции, извлеченные из функций «тембра» из API Echo Nest.
Мы берем среднее значение и ковариацию по всем «сегментам», каждый сегмент описывается 12-мерным вектором тембра.

##### 2) Описание алогоритма:

Нейронная сеть — это громадный распределенный параллельный процессор, состоящий из элементарных единиц обработки информации, накапливающих экспериментальные знания и предоставляющих их для последующей обработки.
Нейронные сети обычно используют для классификации. Сигналы проходят через слои нейронов и обобщаются в один из нескольких классов. Однако их также можно адаптировать в регрессионные модели, если изменить последнюю функцию активации. Необходимо  поменять нелинейную функцию (например, sigmoid или RELU) на линейную, чтобы выходной сигнал можно было отобразить на множество значений, выходящих за пределы фиксированных классов. Таким образом, на выходе будет не вероятность отнесения входного сигнала к какому-либо одному классу, а непрерывное значение, на котором фиксирует свои наблюдения нейронная сеть.
Значит, можно сказать, что нейронная сеть решает задачу регрессии, то есть она выдает прогнозируемое значение переменной, зависимое от множества входных параметров.
Перед тем, как производить прогноз, алгоритм обучается на тренировочном наборе данных — обучающей выборке. Каждая строка такой выборки содержит:
•	в полях, обозначенных как входные — множество входных параметров;
•	в поле, обозначенном как выходное — соответствующее входным параметрам значение зависимой переменной.
Технически обучение заключается в нахождении весов — коэффициентов связей между нейронами. В процессе обучения нейронная сеть способна выявлять сложные зависимости между входными параметрами и выходными, а также выполнять обобщение. Это значит, что в случае успешного обучения Нейросеть способна выдать верный результат на основании данных, которые отсутствовали в обучающей выборке, а также на неполных и/или «зашумленных», частично искажённых данных.
Для задач регрессии чаще всего применяются: 
‒ среднее квадратичное отклонение (mean square error – MSE);
‒ среднее абсолютное отклонение (mean absolute error – MAE).
MSE – это среднее квадратов всех отклонений предсказанных значений от
истинных. Квадрат нужен для того, чтобы избежать отрицательных значений.
Таким образом, данная метрика тем лучше, чем ближе ее значение к нулю
(отсюда диапазон значений данной метрики от 0 до +∞). У нее есть
определенные недостатки. Из-за наличия квадрата она завышает значение
больших ошибок (больше единицы) и преуменьшает значение ошибок, значение которых меньше единицы.
MAE – это среднее абсолютных значение всех отклонений. Выполняет те
же функции, что и MSE, но является более интерпретируемой, так как берет
ошибки по модулю, не выполняя нелинейного преобразования.
Нейронной сети, чтобы обучаться, также нужна какая-то мера. Она должна
уметь сравнить свой ответ с верным ответом из учебного ответа, оценить,
насколько ее ответ близок к истине или далек от нее, а затем с помощью
специального алгоритма обратного распространения ошибки обновить все свои веса. Эта функция должна быть дифференцируемой, чтобы в дальнейшем нейронная сеть смогла посчитать производные по этой функции и определить градиент данной функции. Так как данная функция определяет, насколько нейронная сеть ошиблась, то ее принято называть функцией потерь (loss function). Для данной задачи  метрик функциями потерь могут послужить MAE, MSE.
За сам процесс распространения посчитанной ошибки обратно на все веса модели нейронной сети отвечают так называемые оптимизаторы. Это функции, которые распространяют ошибку, используя различные стратегии: ‒ SGD – стохастический градиентный спуск; 
‒ RMSprop – модификация градиентного спуска; 
‒ Adam – модификация градиентного спуска.
Также процесс обучения нейронной сети способен настраивать лишь веса модели и смещения нейронов. Смещения и веса нейронов – это параметры нейронной сети. Но существует ряд параметров, которые нельзя эффективно настроить в процессе обучения нейронной сети. Они задаются еще до начала обучения и в процессе обучения не изменяются. Такие параметры называются гиперпараметрами нейронной сети. К ним относятся: количество слоев нейронной сети; количество нейронов в слое нейронной сети;  количество эпох обучения;  скорость обучения;  размер обучающей выборки; функции активации;  функция ошибок.



    
## License

Copyright (c) 2022-present, - Shnyra Bogdan